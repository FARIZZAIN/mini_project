{"ast":null,"code":"var _s = $RefreshSig$();\nimport { useState } from \"react\";\nconst useVoiceInput = (onResult, selectedLanguage) => {\n  _s();\n  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n  const [listening, setListening] = useState(false);\n  if (!SpeechRecognition) {\n    return {\n      listening: false,\n      startListening: () => alert(\"Your browser does not support speech recognition.\")\n    };\n  }\n  const recognition = new SpeechRecognition();\n  recognition.continuous = false;\n  recognition.interimResults = false;\n  recognition.onstart = () => setListening(true);\n  recognition.onend = () => setListening(false);\n  recognition.onresult = event => {\n    const transcript = event.results[0][0].transcript;\n    onResult(transcript);\n  };\n  const startListening = () => {\n    recognition.lang = selectedLanguage;\n    recognition.start();\n  };\n  return {\n    listening,\n    startListening\n  };\n};\n_s(useVoiceInput, \"I/31IbK0i+bM5IJ1/ONKGYhqEHw=\");\nexport default useVoiceInput;","map":{"version":3,"names":["useState","useVoiceInput","onResult","selectedLanguage","_s","SpeechRecognition","window","webkitSpeechRecognition","listening","setListening","startListening","alert","recognition","continuous","interimResults","onstart","onend","onresult","event","transcript","results","lang","start"],"sources":["C:/Tutor/react-website/src/components/Voiceinput.js"],"sourcesContent":["import { useState } from \"react\";\r\n\r\nconst useVoiceInput = (onResult, selectedLanguage) => {\r\n  const SpeechRecognition =\r\n    window.SpeechRecognition || window.webkitSpeechRecognition;\r\n  const [listening, setListening] = useState(false);\r\n\r\n  if (!SpeechRecognition) {\r\n    return {\r\n      listening: false,\r\n      startListening: () => alert(\"Your browser does not support speech recognition.\"),\r\n    };\r\n  }\r\n\r\n  const recognition = new SpeechRecognition();\r\n  recognition.continuous = false;\r\n\r\n\r\n  \r\n  recognition.interimResults = false;\r\n\r\n  recognition.onstart = () => setListening(true);\r\n  recognition.onend = () => setListening(false);\r\n\r\n  recognition.onresult = (event) => {\r\n    const transcript = event.results[0][0].transcript;\r\n    onResult(transcript);\r\n  };\r\n\r\n  const startListening = () => {\r\n    recognition.lang = selectedLanguage; \r\n    recognition.start();\r\n  };\r\n\r\n  return { listening, startListening };\r\n};\r\n\r\nexport default useVoiceInput;\r\n\r\n"],"mappings":";AAAA,SAASA,QAAQ,QAAQ,OAAO;AAEhC,MAAMC,aAAa,GAAGA,CAACC,QAAQ,EAAEC,gBAAgB,KAAK;EAAAC,EAAA;EACpD,MAAMC,iBAAiB,GACrBC,MAAM,CAACD,iBAAiB,IAAIC,MAAM,CAACC,uBAAuB;EAC5D,MAAM,CAACC,SAAS,EAAEC,YAAY,CAAC,GAAGT,QAAQ,CAAC,KAAK,CAAC;EAEjD,IAAI,CAACK,iBAAiB,EAAE;IACtB,OAAO;MACLG,SAAS,EAAE,KAAK;MAChBE,cAAc,EAAEA,CAAA,KAAMC,KAAK,CAAC,mDAAmD;IACjF,CAAC;EACH;EAEA,MAAMC,WAAW,GAAG,IAAIP,iBAAiB,CAAC,CAAC;EAC3CO,WAAW,CAACC,UAAU,GAAG,KAAK;EAI9BD,WAAW,CAACE,cAAc,GAAG,KAAK;EAElCF,WAAW,CAACG,OAAO,GAAG,MAAMN,YAAY,CAAC,IAAI,CAAC;EAC9CG,WAAW,CAACI,KAAK,GAAG,MAAMP,YAAY,CAAC,KAAK,CAAC;EAE7CG,WAAW,CAACK,QAAQ,GAAIC,KAAK,IAAK;IAChC,MAAMC,UAAU,GAAGD,KAAK,CAACE,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAACD,UAAU;IACjDjB,QAAQ,CAACiB,UAAU,CAAC;EACtB,CAAC;EAED,MAAMT,cAAc,GAAGA,CAAA,KAAM;IAC3BE,WAAW,CAACS,IAAI,GAAGlB,gBAAgB;IACnCS,WAAW,CAACU,KAAK,CAAC,CAAC;EACrB,CAAC;EAED,OAAO;IAAEd,SAAS;IAAEE;EAAe,CAAC;AACtC,CAAC;AAACN,EAAA,CAjCIH,aAAa;AAmCnB,eAAeA,aAAa","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}